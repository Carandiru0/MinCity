#version 450
#extension GL_GOOGLE_include_directive : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_ballot: enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_shuffle: enable
//#extension GL_KHR_shader_subgroup_quad : enable
#extension GL_EXT_control_flow_attributes : enable

/* Copyright (C) 20xx Jason Tully - All Rights Reserved
 * You may use, distribute and modify this code under the
 * terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License
 * http://www.supersinfulsilicon.com/
 *
This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/
or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.
 */

#include "common.glsl"
#include "light.glsl"


#define GROUP_SIZE_XYZ 8

layout (local_size_x = GROUP_SIZE_XYZ, local_size_y = GROUP_SIZE_XYZ, local_size_z = GROUP_SIZE_XYZ) in;	

// SEED uses PING output, hardcoded, however SEED input requires pc.index_input
layout (push_constant) restrict readonly uniform PushConstant {
	layout(offset=0) int		current_step;		//  JFA
	layout(offset=4) uint		index_output;		// __---->_________________________________________________________________
	layout(offset=8) uint		index_input;        // __<----_________________________________________________________________
} pc;

#define LIGHT 0
#define OPACITY 1

layout (binding = 0) uniform sampler3D seedMap;	// lightprobe map
layout (binding = 1) uniform sampler3D pingpongTexture[2]; // sampling the "ping"
layout (binding = 2, rgba16) writeonly restrict uniform image3D pingpongImage[2];	// storing the "pong", -only to be used with imageStore (writeonly)
//////////////////////////////////////////////////////////////////////////////////
layout (binding = 3, rgba16) writeonly restrict uniform image3D outTemporalDDFinal; // (distance & direction) final output --only to be used with imageStore (writeonly) // only signed normalized values
layout (binding = 4, rgba16f) writeonly restrict uniform image3D outTemporalCFinal; // (color) final filtered output

// "World Visible Volume"
layout (constant_id = 0) const float WorldDimensions = 0.0f;
layout (constant_id = 1) const float InvWorldLength = 0.0f;

// "Light Volume"
layout (constant_id = 2) const float VolumeDimensions = 0.0f;
layout (constant_id = 3) const float InvVolumeDimensions = 0.0f;

layout (constant_id = 4) const float VOX_SIZE = 0.0f;

#define warp_local vec4

// 26 neighbours + self at i==13 (*compiletime* offset)
#define next_neighbour_offset(i) ivec3((i / 9) - 1, (i / 3 % 3) - 1, (i % 3) - 1)
/*
ivec3 next_neighbour_offset(const in int i) // constant values only (compile time only)   [generated local compile time constant vector values for an offset to a neighbour]
{										    //                                             -operation is evaluated during compile, no integer divides or modulus actually take place at run time.
	return(ivec3((i / 9) - 1, (i / 3 % 3) - 1, (i % 3) - 1)); //                             -constants are generated as this function gets iterated
}															  //                             -saves using an enormous # of scalar constants or a runtime nested for loop that handles self aswell.
*/															  //							 -self is skipped below

// 26 neighbours (no center sample) [optimal memory access pattern]
/*const ivec3 offsets[] = ivec3[]( ivec3(-1, -1, -1),
								 ivec3(0, -1, -1),
								 ivec3(1, -1, -1),
								 ivec3(-1, 0, -1),
								 ivec3(0, 0, -1),
								 ivec3(1, 0, -1),
								 ivec3(-1, 1, -1),
								 ivec3(0, 1, -1),
								 ivec3(1, 1, -1),
								
								 ivec3(-1, -1, 0),
								 ivec3(0, -1, 0),
								 ivec3(1, -1, 0),
								 ivec3(-1, 0, 0),
								 ivec3(1, 0, 0),
								 ivec3(-1, 1, 0),
								 ivec3(0, 1, 0),
								 ivec3(1, 1, 0),
								
								 ivec3(-1, -1, 1),
								 ivec3(0, -1, 1),
								 ivec3(1, -1, 1),
								 ivec3(-1, 0, 1),
								 ivec3(0, 0, 1),
								 ivec3(1, 0, 1),
								 ivec3(-1, 1, 1),
								 ivec3(0, 1, 1),
								 ivec3(1, 1, 1) );
*/
// 
// -----------------------------------------------------------------
// [light emitter 10bpc relative position]  +  [hdr 10bpc rgb color] 
// -----------------------------------------------------------------
//
// 16bpc
//             warp.x             warp.y             warp.z             warp.w
// 0x1111111111111111 0x1111111111111111 0x1111111111111111 0x1111111111111111
//   0xxxxxxxxxxyyyyy   0yyyyyzzzzzzzzzz   0rrrrrrrrrrggggg   0gggggbbbbbbbbbb
//
// (highest bit always unused for each component)
//
// packed component:      bit count:      packed component mask to value:
// x : 10 bits, 0 - 1023       10,                  x : (0x7fe0 & warp.x) >> 5
// y : "  ""   "   ""          20,                  y : ((0x1f & warp.x) << 5) | ((0x7c00 & warp.y) >> 10)
// z : "  ""   "   ""          30,                  z : (0x3ff & warp.y)
// r : 10 bits, 0 - 1023       40,                  r : (0x7fe0 & warp.z) >> 5
// g : "  ""   "   ""          50,                  g : ((0x1f & warp.z) << 5) | ((0x7c00 & warp.w) >> 10)
// b : "  ""   "   ""          60,                  b : (0x3ff & warp.w)
// 0 : 4 bits, unused          64 bits total        0 : each high bit in each component is unused and set to 0
//
// xyz is packed into xy  -  position
// rgb is packed into zw  -  color
// --------------------------------------------------------------------
#define packed_position xy
#define packed_color zw

#define FDATA_MAX 1023.0f

vec3 _decode_warp_vector( in const uvec2 encoded )  // [private] do not call directly (internal)
{
	uvec3 decoded;
	decoded.x = (0x7fe0u & encoded.x) >> 5u;
	decoded.y = ((0x1fu & encoded.x) << 5u) | ((0x7c00u & encoded.y) >> 10u);
	decoded.z = (0x3ffu & encoded.y);

	return(vec3(decoded));
}
uvec2 _encode_warp_vector( in const uvec3 decoded )  // [private] do not call directly (internal)
{
	uvec2 encoded;
	encoded.x = (0x7fe0u & (decoded.x << 5u))  | ((0x3e0u & decoded.y) >> 5u);
	encoded.y = ((0x1fu & decoded.y) << 10u) | (0x3ffu & decoded.z);

	return(encoded);
}

vec3 decode_warp_location( in const warp_local warp ) // [public] when only location is required, location returned
{
	const uvec4 encoded = uvec4(warp * 65535.0f).wzyx;

	// scaling position data back to world limits from data levels
	return(_decode_warp_vector(encoded.packed_position) / FDATA_MAX * WorldDimensions);
}

vec4 decode_warp( in const warp_local warp ) // [public] location & packed hdr color returned
{
	const uvec4 encoded = uvec4(warp * 65535.0f).wzyx;

	            // scaling position data back to world limits from data levels               // 10bpc rgb hdr color
	return(vec4(_decode_warp_vector(encoded.packed_position) / FDATA_MAX * WorldDimensions, packColorHDR(_decode_warp_vector(encoded.packed_color) / FDATA_MAX)));
}

void decode_warp( out vec3 location, out vec3 color, in const warp_local warp ) // [public] location & unpacked color out parameters
{
	const uvec4 encoded = uvec4(warp * 65535.0f).wzyx;

	location = _decode_warp_vector(encoded.packed_position) / FDATA_MAX * WorldDimensions; // scaling position data back to world limits from data levels
	color = _decode_warp_vector(encoded.packed_color) / FDATA_MAX; // 10bpc rgb hdr color
}

// *do not remove*
vec4 encode_warp( in const vec3 location, in const vec3 color ) // [public] returns a normalized, unorm ready, 10bpc ready packed position & 10bpc hdr color - ready for store
{                                               // normalize and then scale to data level maximum for increased (double) precision
	return(vec4(_encode_warp_vector(uvec3(floor(location / WorldDimensions * FDATA_MAX))), _encode_warp_vector(uvec3(color * FDATA_MAX))).wzyx / 65535.0f);
}

#undef packed_position
#undef packed_color

bool isEmitter(in const vec4 warp)
{
	return(any(notEqual(vec2(0), warp.zw))); // check for non-zero color in the last 2 components which are dedicated to 10bpc color
}

// seed uses the source uploaded light, selecting the correct input based on the current frames resource index
#ifdef SEED
vec4 sampleInputVolume( in const vec3 read_location )
{
    const ivec3 iread_location = ivec3(floor(read_location + 0.5f));

	vec4 last = texelFetch(pingpongTexture[pc.index_input], iread_location, 0);
	vec4 now  = texelFetch(seedMap, iread_location, 0);
	const bvec2 emitter = bvec2(isEmitter(last), isEmitter(now));

	float dd = 1.0f;

	if (emitter.x) {
		last = decode_warp(last);
		dd = 0.5f;
	}

	if (emitter.y) {
		now = decode_warp(now);
		dd = mix(dd, getAttenuation(distance(last.xyz, now.xyz) * VOX_SIZE), emitter.x);
	}

	const vec3 color = mix(unpackColorHDR(last.a), unpackColorHDR(now.a), dd);   // last.a and/or now.a resolve to zero if already zero so safe to interpolate color if partial emitter
	                                                                             // if either is not zero, they will blend based on inverse square law between both emitters if they both exist, or will contribute half of it's value otherwise. in cases where last does not exist, and now does, it simply resolves straight to now.
	return( encode_warp(now.xyz, color) ); // will still resolve to zero in now is already zero at this point here (not an emitter), otherwise the resolved value from previous operations is encoded correctly.
}
#else
vec4 sampleInputVolume( in const vec3 read_location )
{
	return( texelFetch(pingpongTexture[pc.index_input], ivec3(floor(read_location + 0.5f)), 0) );
}
#endif

// ###################################################################################################################################
#define localToGlobal(local) fma(gl_WorkGroupID.xyz, vec3(GROUP_SIZE_XYZ), local)

#if !defined(MIP) && !defined(SEED) // *bugfix adds + 1 to the number of elements in X. This changes the memory access pattern so that the offset is +1, diagonalizing the accesses into a unique bank for each memory access. avoids all bank conflicts, with each memory access they can now execute concurrently. **do not change** lookup solving LDS bank conflicts (shared memory)

//  2D Example
//  Each # (access)
//  is unique in the column that it is in,
//  as each row is sequentially accessed:
//              
//  |-----    BANKS    ----| +1 extra element per row
//  |                      |
//  |0  1  2  3  4  5  6  7|  8
//  |1  2  3  4  5  6  7  8|  9
//  |2  3  4  5  6  7  8  9| 10
//  |3  4  5  6  7  8  9 10| 11
//  |4  5  6  7  8  9 10 11| 12
//  |5  6  7  8  9 10 11 12| 13
//  |6  7  8  9 10 11 12 13| 14
//  |7  8  9 10 11 12 13 14| 15
//
//
shared vec4 warp_lds[GROUP_SIZE_XYZ + 1][GROUP_SIZE_XYZ][GROUP_SIZE_XYZ]; // *do not remove +1 padding on X*

void populateLDS(in const vec4 warp, in const ivec3 local_location) {

	warp_lds[local_location.x][local_location.y][local_location.z] = warp;
	barrier(); // required so that lds is coherent between the last write and now reads (memorybarriershared is included in barrier too)
}
//vec3(VolumeDimensions_Width, VolumeDimensions_Depth, VolumeDimensions_Height)
vec4 group_load( in const ivec3 local_location ) {

	const bool bZero = all(greaterThanEqual(local_location, ivec3(0)));
	const bool bGroup = bZero && all(lessThan(local_location, ivec3(GROUP_SIZE_XYZ)));

	[[branch]] if (subgroupAll( bGroup ) || bGroup) { // fast subgroup & group paths

		return( warp_lds[local_location.x][local_location.y][local_location.z] );
	}
	// regular path - border texture addressing on texture sampler so out of bounds are handled with no light returned.
	return( sampleInputVolume(localToGlobal(local_location)) );
	
	/*
	return(
	subgroupAll(all(greaterThanEqual(location, ivec3(0))) && all(lessThan(location, ivec3(GROUP_SIZE)))) ?
		warp_lds[location.x][location.y][location.z]
		:
		sampleInputVolume(ilocalToGlobal(location))
	);
	*/
}


void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	if ( isEmitter(read_warp) ) {	// new ? 
			
		const float read_distance = distance(decode_warp_location(read_warp), current_location);

		const bool bLess = read_distance < current_distance;
			
		movc(bLess, current_distance, read_distance);
		movc(bLess, warp, read_warp);
	}
}

/*
void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	[[branch]] if ( isEmitter(read_warp) ) {	// new
			
		const float read_distance = distance(decode_warp_location(read_warp), current_location);

		current_distance = subgroupMin(min(current_distance, read_distance));
		
		// acquire id of the active invocation that contains the least distance
		const uint active_invocation_id = subgroupBallotFindMSB(subgroupBallot(read_distance == current_distance));
		
		// every other invocation acquires the active_invocation's warp, which is the location and color of the light that was deemed the closest across the entire subgroup.
		warp = subgroupShuffle(read_warp, active_invocation_id);
	}
}
*/

/*
void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	const bool lit = isLit(read_warp.packed_color);
	const float read_distance = lit ? distance(read_warp.emitter_location, current_location) : 99999.99999f;

	current_distance = subgroupMin(read_distance);

	// acquire id of the active invocation that contains the least distance
	const uint active_invocation_id = subgroupBallotFindMSB(subgroupBallot(read_distance == current_distance));
		
	// every other invocation acquires the active_invocation's warp, which is the location and color of the light that was deemed the closest across the entire subgroup.
	[[branch]] if ( isLit(read_warp.packed_color) ) {	// new
		
	
	warp = subgroupShuffle(read_warp, active_invocation_id);

	}
}*/

void propogateBlocks(inout warp_local warp, in const vec3 current_location, in const bool emitter)
{
	float current_distance = mix(9999999.9999999f, distance(decode_warp_location(warp), current_location), emitter);
	
	// 13th iteration is an offset of 0,0,0 which is no offset or sampling self (skip)
	#define T(i) \
		propogateBlock(warp, current_distance, current_location, ivec3(gl_LocalInvocationID.xyz) + next_neighbour_offset(i) * pc.current_step); \
	
	// unrolled and compile time constant for offset generated. skip 13, self.
	T(0);  T(1);  T(2);  T(3);  T(4);  T(5);  T(6);  T(7);  T(8);
	T(9);  T(10); T(11); T(12); T(14); T(15); T(16); T(17); T(18);
	T(19); T(20); T(21); T(22); T(23); T(24); T(25); T(26); // 26 texel

	#undef T
}

#endif // not MIP or SEED

#if !defined(MIP) // is *not* MIP  -- pingponging or seed

void main() 
{
	const vec3 global_invocation_id = localToGlobal(gl_LocalInvocationID.xyz);

	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(global_invocation_id - VolumeDimensions, vec3(0))) )
			return;
	}

	warp_local warp = sampleInputVolume(global_invocation_id);   /// if SEED is defined this is a simple texelFetch & imageStore (copy)

#ifndef SEED
	const bool emitter = any(notEqual(vec2(0), warp.zw));

	if (subgroupAny(emitter)) { // hints to compiler that emitter variable is scalar, so less vector registers are used

		populateLDS(warp, ivec3(gl_LocalInvocationID.xyz));  // value is properly initialized.
		 
		// SEED doesn't 1+JFA anymore, unless proven it is not messing with the fractional offset.
		propogateBlocks(warp, (global_invocation_id * InvVolumeDimensions * WorldDimensions), emitter);
	}
	else { // still have to satisy currently empty with potential lit neighbour, here it is not scalar and vector registers are used.

		populateLDS(warp, ivec3(gl_LocalInvocationID.xyz));  // value is properly initialized.

		// SEED doesn't 1+JFA anymore, unless proven it is not messing with the fractional offset.
		propogateBlocks(warp, (global_invocation_id * InvVolumeDimensions * WorldDimensions), emitter); 
	}
#endif

	imageStore(pingpongImage[pc.index_output], ivec3(localToGlobal(gl_LocalInvocationID.xyz)), warp);
}

#endif // not MIP


// ###################################################################################################################################
#if defined(MIP) // FILTER STEP
		
float emitter_to_distance(in const vec3 emitter_location, in const vec3 current_location)
{
	return(distance(emitter_location, current_location));
}
float normalize_distance(in const float d) // normalized distance, [0.0f ... 1.0f]
{
	return(clamp(d * InvWorldLength, 0.0f, 1.0f));
}

/* deprecated for non temporal replacement sample_warp()
// smin removes discontuities (voronoi edges) by blending distance field data correctly
void temporalBlendDD( in const restrict sampler3D inputTemporalDD, inout vec3 direction, inout float dist, in const vec3 uvw )
{
	// input Distance, Direction, are initialized to the locations first sample
	const float blending = 0.01f;
	vec4 neighbour;

	neighbour = textureLod(inputTemporalDD, fma(vec3(-0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,-0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,-0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]
}		
*/
/*
vec3 temporalBlendR( in const restrict sampler3D inputTemporalR, in vec3 color, in const vec3 uvw )
{
	// input color is initialized to the locations first sample

	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,1)).rgb;

	return(color * (1.0f/7.0f)); // 6 neighbour samples + 1 center sample
}
/*
vec3 temporalBlendC( in const restrict sampler3D inputTemporalC, in const restrict sampler3D inputTemporalDD, in vec3 color, in const vec3 uvw, in const float d0 )
{
	// this is the correct physical way of blending colors of light, additive blending of adjacent light colors (no mixing)
	// with additive blending light will accumulate to white in area's of bright mixed colors as it correctly should intensify with nearby lighting

	float emission = getAttenuation(d0);

	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(-1,0,0)).a * 0.5f + 0.5f);
	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(1,0,0)).a * 0.5f + 0.5f);
	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,-1,0)).a * 0.5f + 0.5f);
	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,1,0)).a * 0.5f + 0.5f);
	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,-1)).a * 0.5f + 0.5f);
	emission += getAttenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,1)).a * 0.5f + 0.5f);

	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,1)).rgb;

	// "One important note here is that we normalise pixel emissive on total number of rays, but pixel colour on the 
	// total accumulated emissive. This means the colour value maintains it’s magnitude (or brightness) regardless 
	// of how many rays were cast or surfaces hit. E.g. if we cast 32 rays and only 1 of them hit a red emitter, 
	// we want all of that red colour to contribute to the final pixel colour."
	// https://samuelbigos.github.io/posts/2dgi1-2d-global-illumination-in-godot.html

	// 7 samples total
	color /= emission;
	emission /= 7.0f;

	return(emission * color);
}
*/

#define emitter_location xyz
#define packed_color w

// this function removes the edges in the voronoi structure by making neighbours accurate (minimum distance to light/per voxel)
// it also calculates the lighting color contributed by all neighbours
void sample_warp(in const restrict sampler3D pingpong, in const vec3 uvw, inout vec4 current_direction_distance, inout vec3 current_color, in const vec3 current_location) 
{	
	warp_local neighbour_warp;
	float neighbour_distance;

	// 1 center
	current_color = current_color * getAttenuation(current_direction_distance.w * VOX_SIZE);
	
	// 26 neighbours
	// 13th iteration is an offset of 0,0,0 which is no offset or sampling self (skip)
	// *bugfix - accumulated half angle vectors results in anti-aliased, continous direction vectors. Far better than selecting a min direction which causes a discontunity between 2 light sources.
#define T(i) \
	neighbour_warp = decode_warp(textureLodOffset(pingpong, uvw, 0, next_neighbour_offset(i))); \
	neighbour_distance = emitter_to_distance(neighbour_warp.emitter_location, current_location); \
	if (neighbour_distance < current_direction_distance.w) { \
		current_direction_distance = vec4(neighbour_warp.emitter_location, neighbour_distance); \
	} \
	current_color += unpackColorHDR(neighbour_warp.packed_color) * getAttenuation(neighbour_distance * VOX_SIZE); \

	//current_direction_distance.xyz = normalize(current_direction_distance.xyz + neighbour_direction_distance.xyz); 
	//current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w); 

	// unrolled and compile time constant for offset generated. skip 13, self.

	//T(12); T(4);  T(3);  T(10); T(9);  T(1);  T(0);  // 7 trilinear (negative offset)
	//T(14); T(22); T(23); T(16); T(17); T(25); T(26); // 7 trilinear (positive offset)

	T(12); T(4);  T(3);  T(10); T(9);  T(1);  T(0);  // 7 trilinear (negative offset)    // *bugfix - this is balanced so the - 0.5f offset does not create a "border" on one extent of the 3D texture
	T(14); T(22); T(23); T(16); T(17); T(25); T(26); // 7 trilinear (positive offset)

	//T(0);  T(1);  T(2);  T(3);  T(4);  T(5);  T(6);  T(7);  T(8);
	//T(9);  T(10); T(11); T(12); T(14); T(15); T(16); T(17); T(18);
	//T(19); T(20); T(21); T(22); T(23); T(24); T(25); T(26); // 26 texel

#undef T
}

void main() 
{
	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(gl_GlobalInvocationID.xyz - VolumeDimensions, vec3(0))) )
			return;
	}

	const warp_local current_warp = decode_warp(textureLod(pingpongTexture[pc.index_input], (gl_GlobalInvocationID.xyz - 0.5f) * InvVolumeDimensions, 0));
	vec3 current_color = unpackColorHDR(current_warp.packed_color);
	const vec3 original_color = current_color;

	float d = 0.0f;

	// #################################################################################################################
	{	// distance & direction ###
		
		const vec3 current_location = (gl_GlobalInvocationID.xyz * InvVolumeDimensions * WorldDimensions);

		vec4 current_direction_distance = vec4(current_warp.emitter_location, emitter_to_distance(current_warp.emitter_location, current_location));
		
		sample_warp(pingpongTexture[pc.index_input], (gl_GlobalInvocationID.xyz - 0.5f) * InvVolumeDimensions, current_direction_distance, current_color, current_location);

		current_direction_distance.xyz = current_direction_distance.xyz / WorldDimensions; // normalize position for 16bpc unorm packing. emitter positions are always small, unsigned, fitting accurately into 16 bits per component (x,y,z) 
		current_direction_distance.w = d = normalize_distance(current_direction_distance.w); // normalize distance to range [0,1] for 16bpc unorm texture precision usage

		imageStore(outTemporalDDFinal, ivec3(gl_GlobalInvocationID.xyz), current_direction_distance);
	}

	{   // color ###
		
		{ // light
			// Input sample of blended area, see : 
			// https://www.shadertoy.com/view/fdjXDD

			imageStore(outTemporalCFinal, ivec3(gl_GlobalInvocationID.xyz), vec4(mix(original_color, current_color, getAttenuation(d * VOX_SIZE)), 1.0f)); // *do not change* increases accuracy as lights get closer to the current location by an order of magnitude!
		}
	}



/*
	
	vec4 temporal_volume_sum_direction_distance;
	vec3 temporal_volume_sum_color;
	
	const ivec3 iLocation = ivec3(gl_GlobalInvocationID.xyz);
	
	{ // input index is off by one for final accumulated output is no included. Only the raw current values propogate thru the temporal history

		// ### sample oldest (1), begin result. note: this volume gets popped off the "queue"
		temporal_volume_sum_direction_distance = texelFetch(inTemporalDD[1], iLocation, 0);								// read 2
		temporal_volume_sum_color = texelFetch(inTemporalC[1], iLocation, 0).rgb;										// read 2

		{ // ### sample old, add to result, then old moves to 1. note: this volume gets popped to back of "queue"
			{
				const vec4 temporal_volume = texelFetch(inTemporalDD[0], iLocation, 0);									// read 1
				temporal_volume_sum_direction_distance += temporal_volume;					
				imageStore(outTemporalDD[2], iLocation, temporal_volume);												// overwrite 2 with 1
			}
			{
				const vec3 temporal_volume = texelFetch(inTemporalC[0], iLocation, 0).rgb;								// read 1
				temporal_volume_sum_color += temporal_volume;
				imageStore(outTemporalC[2], iLocation, temporal_volume.rgbb);											// overwrite 2 with 1
			}	
		}
	}
	
	#define _direction xyz
	#define _distance a

	// sample new, add to result, then new moves to 0. note: this volume gets pushed to front of "queue"

	{   // sampling ###
		vec3 source_location;
		{
			vec3 source_color;
			sampleInputVolumeAA(source_location, source_color, iLocation);

			// color ###
			temporalBlendC(source_color);

			imageStore(outTemporalC[1], iLocation, source_color.rgbb);													// overwrite 1 with current
			temporal_volume_sum_color += source_color;

			// ### temporal supersampled output - result moves to output
			temporal_volume_sum_color = temporal_volume_sum_color * pc.inv_temporal_size;
			imageStore(outTemporalC[0], iLocation, temporal_volume_sum_color.rgbb);										// overwrite 0 with accumulated (final output)
		}

		// distance & direction ###
		const vec3 current_location = gl_GlobalInvocationID.xyz * InvVolumeDimensions * WorldDimensions;
		const vec3 direction = source_location - current_location;

		// normalization
		vec4 source;
		source._distance = length(direction) * pc.inv_max_distance * 2.0f - 1.0f;  // normalized distance, expanded to [-1.0f...1.0f] to leverage full range of 16bit signed texture
		// transforms world space position of light to view space
		// mat3 of view only required to transform a normal / direction vector		// this is a bug fix weird but works well enough 
																					// this is the half angle between light direction and view'ish vector
																					// eliminates most of the "bright building" in top left corner problem
																					// other option is to completely rip out direction which won't look as good
																					// its a hack but - its satisfactory visually (hard problem to solve this late with lighting being "done")

		source._direction = transformNormalToViewSpace(mat3(pc.view), normalize(direction).xzy).xzy;  // direction is natively width,depth,height
																					// view is width, height, depth
																					// so the mul, direction is swizzled to be compatible with view
																					// then finally swizzled back to width,depth,height
																					// which is the final form we want for fragment shaders
		const float saved_raw_distance = source._distance;

		temporalBlendDD(source._direction, source._distance, iLocation);

		imageStore(outTemporalDD[1], iLocation, source);	
		temporal_volume_sum_direction_distance += source;

		// ### temporal supersampled output - result moves to output

		// // get absolute difference (for vectors, the data, does not require usuage of abs)
		// see: https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixsub.htm
		temporal_volume_sum_direction_distance = temporal_volume_sum_direction_distance * pc.inv_temporal_size;
		const float distance_diff = (temporal_volume_sum_direction_distance._distance - saved_raw_distance); // no abs is important
		temporal_volume_sum_direction_distance._distance = temporal_volume_sum_direction_distance._distance - distance_diff; // remove difference - removes ghosting
													// only distance needs this correction
													// direction alone has no ghosting effect, and is supersampled without correction
	
		imageStore(outTemporalDD[0], iLocation, temporal_volume_sum_direction_distance);
	}
*/
}
#endif



