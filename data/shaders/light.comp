#version 460
#extension GL_GOOGLE_include_directive : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_EXT_control_flow_attributes : enable

/* Copyright (C) 20xx Jason Tully - All Rights Reserved
 * You may use, distribute and modify this code under the
 * terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License
 * http://www.supersinfulsilicon.com/
 *
This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/
or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.
 */

#include "common.glsl"
#include "transform.glsl"

#define GROUP_SIZE_XY 8
#define GROUP_SIZE_Z 8 // must match ComputeLightConstants.h

layout (local_size_x = GROUP_SIZE_XY, local_size_y = GROUP_SIZE_XY, local_size_z = GROUP_SIZE_Z) in;	// z is manually set/tweaked see volumetricOpacity.h 8,8,4=256 tested optimal warp size at height 128 and 256 visible voxels

// SEED uses PING output, hardcoded, however SEED input requires pc.index_input
layout (push_constant) restrict readonly uniform PushConstant {
	layout(offset=0) int		current_step;		//  JFA
	layout(offset=4) uint		index_output;		// __|_____________________________________________________________________
	layout(offset=8) uint		index_input;        // index_input                    overlaps / included in both JFA & Filter
	layout(offset=12) uint      index_filter;		//   |
	layout(offset=16) mat4		view;				//   |
													// Filter
} pc;

#define LIGHT 0
#define OPACITY 1

layout (binding = 0) uniform sampler3D seedMap[2];	// lightprobe map
layout (binding = 1) uniform sampler3D pingpongTexture[2]; // sampling the "ping"
layout (binding = 2, rgba32f) writeonly restrict uniform image3D pingpongImage[2];	// storing the "pong", -only to be used with imageStore (writeonly)
//////////////////////////////////////////////////////////////////////////////////
layout (binding = 3) uniform sampler3D inTemporalDD[2];	// (distance & direction) lightmap history // only signed normalized values
layout (binding = 4, rg16_snorm) writeonly restrict uniform image3D outTemporalDD[3]; // (distance & direction) final filtered output + n temporal history volumes -only to be used with imageStore (writeonly) // only signed normalized values
layout (binding = 5) uniform sampler3D inTemporalC[2];	// (color) lightmap history
layout (binding = 6, rgba8) writeonly restrict uniform image3D outTemporalC[2]; // n temporal history volumes -only to be used with imageStore (writeonly)
layout (binding = 7, rgba16f) writeonly restrict uniform image3D outTemporalCFinal; // (color) final filtered output
layout (binding = 8) uniform sampler3D inTemporalR[2];	// (reflection color) lightmap history
layout (binding = 9, rgba8) writeonly restrict uniform image3D outTemporalR[3]; // (reflection color) final filtered output + n temporal history volumes -only to be used with imageStore (writeonly)

// "World Visible Volume"
layout (constant_id = 0) const float WorldDimensions = 0.0f;
layout (constant_id = 1) const float WorldLength = 0.0f;
layout (constant_id = 2) const float InvWorldLength = 0.0f;

// "Light Volume"
layout (constant_id = 3) const float VolumeDimensions_Width = 0.0f;
layout (constant_id = 4) const float VolumeDimensions_Depth = 0.0f;
layout (constant_id = 5) const float VolumeDimensions_Height = 0.0f;
layout (constant_id = 6) const float InvVolumeDimensions_Width = 0.0f;
layout (constant_id = 7) const float InvVolumeDimensions_Depth = 0.0f;
layout (constant_id = 8) const float InvVolumeDimensions_Height = 0.0f;
#define VolumeDimensions vec3(VolumeDimensions_Width, VolumeDimensions_Depth, VolumeDimensions_Height)
#define InvVolumeDimensions vec3(InvVolumeDimensions_Width, InvVolumeDimensions_Depth, InvVolumeDimensions_Height)
layout (constant_id = 9) const float VOX_SIZE = 0.0f;

#define emitter_location xyz
#define packed_color a
#define warp_local vec4

bool isLit( in const float sampled_packed_color )
{
	return( 0.0f != sampled_packed_color );
}

#ifdef SEED
// seed uses the source uploaded light, selecting the correct input based on the current frames resource index
vec4 sampleInputVolume( in const ivec3 Location) // best jfa result with texelFetch
{
	return( texelFetch(seedMap[pc.index_input], Location, 0) );
}
#else
vec4 sampleInputVolume( in const ivec3 Location )
{
	// input image is dynamically set with push constant
	return( texelFetch(pingpongTexture[pc.index_input], Location, 0) );	// best jfa result with texelFetch
}
#endif

// ###################################################################################################################################
#if !defined(MIP)
shared vec4 warp_lds[GROUP_SIZE_XY][GROUP_SIZE_XY][GROUP_SIZE_Z];

#define localToGlobal(local) fma(gl_WorkGroupID.xyz, vec3(GROUP_SIZE_XY, GROUP_SIZE_XY, GROUP_SIZE_Z), local)
#define ilocalToGlobal(local) (ivec3(gl_WorkGroupID.xyz * vec3(GROUP_SIZE_XY, GROUP_SIZE_XY, GROUP_SIZE_Z)) + local)

vec4 populateLDS(in const ivec3 local) {

	const warp_local warp = sampleInputVolume(ilocalToGlobal(local));
	warp_lds[local.x][local.y][local.z] = warp;

	// barrier moved to propogateBlocks
	return( warp );
}
//vec3(VolumeDimensions_Width, VolumeDimensions_Depth, VolumeDimensions_Height)
vec4 group_load(in const ivec3 location) {

	const bool bZero = all(greaterThanEqual(location, ivec3(0)));
	const bool bGroup = bZero && all(lessThan(location, ivec3(GROUP_SIZE_XY, GROUP_SIZE_XY, GROUP_SIZE_Z)));

	if (subgroupAll( bGroup ) || bGroup) { // fast subgroup & group paths

		return( warp_lds[location.x][location.y][location.z] );
	}
	// regular path - border texture addressing on texture sampler so out of bounds are handled with no light returned.
	return( sampleInputVolume(ilocalToGlobal(location)) );
	
	/*
	return(
	subgroupAll(all(greaterThanEqual(location, ivec3(0))) && all(lessThan(location, ivec3(GROUP_SIZE)))) ?
		warp_lds[location.x][location.y][location.z]
		:
		sampleInputVolume(ilocalToGlobal(location))
	);
	*/
}

void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	[[flatten]] if ( isLit(read_warp.packed_color) ) {	// new
			
		const float read_distance = distance(read_warp.emitter_location, current_location);

		[[flatten]] if ( read_distance < current_distance ) {
			
			current_distance = read_distance;
			warp = read_warp;
		}
	}
}
void propogateBlocks(inout warp_local warp)
{
	const vec3 current_location = localToGlobal(gl_LocalInvocationID.xyz) * InvVolumeDimensions * WorldDimensions;
#ifndef SEED
	const int current_step = pc.current_step;
#endif
	float current_distance = 99999999999.9f;
	
	barrier(); // required so that lds is coherent between the last writes and now reads

	ivec3 offset;
	[[unroll]] for (offset.z = -1 ; offset.z <= 1 ; ++offset.z) {
		[[unroll]] for (offset.y = -1 ; offset.y <= 1 ; ++offset.y) {
			[[unroll]] for (offset.x = -1 ; offset.x <= 1 ; ++offset.x) {

#ifdef SEED
				propogateBlock(warp, current_distance, current_location, ivec3(gl_LocalInvocationID.xyz) + offset);
#else
				propogateBlock(warp, current_distance, current_location, ivec3(gl_LocalInvocationID.xyz) + offset * current_step);
#endif
	}}} // for;for;for
}

void main() 
{
/* // this is allowable 128x128x64 divided by local size is ok, no remainder so bounds are respected inherently
	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(gl_GlobalInvocationID.xyz - VolumeDimensions, vec3(0))) )
			return;
	}
*/
	warp_local warp = populateLDS(ivec3(gl_LocalInvocationID.xyz));  // value is properly initialized.
	propogateBlocks(warp);

	imageStore(pingpongImage[pc.index_output], ilocalToGlobal(ivec3(gl_LocalInvocationID.xyz)), warp);
}

#endif // not MIP


// ###################################################################################################################################
#if defined(MIP) // FILTER STEP

float emitter_to_distance(in const vec3 emitter_location, in const vec3 current_location)
{
	return(distance(emitter_location, current_location));
}
float normalize_distance(in const float d) // normalized distance, [0.0f ... 1.0f]
{
	return(d * InvWorldLength * 2.0f - 1.0f);
}
vec3 emitter_to_direction(in const vec3 emitter_location, in const vec3 current_location)
{
	return(normalize(emitter_location - current_location));
}
vec4 emitter_to_direction_distance(in const vec3 emitter_location, in const vec3 current_location)
{
	vec4 current_direction_distance;
	current_direction_distance.xyz = emitter_location - current_location;
	current_direction_distance.w = length(current_direction_distance.xyz);							// optimized normalized direction + distance with one less sqrt
	current_direction_distance.xyz = current_direction_distance.xyz / current_direction_distance.w; // <---normalized

	return(current_direction_distance);
}

// smin removes discontuities (voronoi edges) by blending distance field data correctly
void temporalBlendDD( in const restrict sampler3D inputTemporalDD, inout vec3 direction, inout float dist, in const vec3 uvw )
{
	// input Distance, Direction, are initialized to the locations first sample
	const float blending = 0.01f;
	vec4 neighbour;

	neighbour = textureLod(inputTemporalDD, fma(vec3(-0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);

	neighbour = textureLod(inputTemporalDD, fma(vec3(0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,-0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,-0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w, blending);
}		

vec3 temporalBlendR( in const restrict sampler3D inputTemporalR, in vec3 color, in const vec3 uvw )
{
	// input color is initialized to the locations first sample

	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,1)).rgb;

	return(color * (1.0f/7.0f)); // 6 neighbour samples + 1 center sample
}

/*float attenuation(in const float d)
{
	return(1.0f / fma(d, d, 1.0f));
}
*/
// final inverse square law equation used:
// a = 1.0f / ( (d + 1.0) * (d + 1.0 )
// see : https://www.desmos.com/calculator/hqksaay8ax
float attenuation(in float light_distance)  // this is half of the equation, when light volume is sampled, the other half is calculated. They than combine to make the full equation as above. This seems to be the most accurate for distance.
{
	return( 1.0f / (light_distance + 1.0f) );
}

vec3 sampleC(in const restrict sampler3D inputC, in vec3 color, in const vec3 current_location, in const float d0) 
{
	const float volume_distance = d0 * length(VolumeDimensions);

	color = color * attenuation(d0 * WorldLength * VOX_SIZE);

	vec4 neighbour;
	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(-1,0,0)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(1,0,0)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(0,-1,0)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(0,1,0)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(0,0,-1)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	neighbour = textureLod(inputC, (gl_GlobalInvocationID.xyz + volume_distance * vec3(0,0,1)) * InvVolumeDimensions, 0);
	color += unpackColor(neighbour.packed_color) * attenuation(distance(current_location, neighbour.emitter_location) * VOX_SIZE);

	return(color);
}

vec3 temporalBlendC( in const restrict sampler3D inputTemporalC, in const restrict sampler3D inputTemporalDD, in vec3 color, in const vec3 uvw, in const float d0 )
{
	// this is the correct physical way of blending colors of light, additive blending of adjacent light colors (no mixing)
	// with additive blending light will accumulate to white in area's of bright mixed colors as it correctly should intensify with nearby lighting

	float emission = attenuation(d0);

	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(-1,0,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(1,0,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,-1,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,1,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,-1)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,1)).a * 0.5f + 0.5f);

	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,1)).rgb;

	// "One important note here is that we normalise pixel emissive on total number of rays, but pixel colour on the 
	// total accumulated emissive. This means the colour value maintains it’s magnitude (or brightness) regardless 
	// of how many rays were cast or surfaces hit. E.g. if we cast 32 rays and only 1 of them hit a red emitter, 
	// we want all of that red colour to contribute to the final pixel colour."
	// https://samuelbigos.github.io/posts/2dgi1-2d-global-illumination-in-godot.html

	// 7 samples total
	color /= emission;
	emission /= 7.0f;

	return(emission * color);
}

//const vec3 fix_direction = normalize(vec3(1,0,-1));
void main() 
{
/* // this is allowable 64x64x128 divided by local size 8,8,8 is ok, no remainder so bounds are respected inherently
	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(gl_GlobalInvocationID.xyz - VolumeDimensions, vec3(0))) )
			return;
	}
*/

	const ivec3 iLocation = ivec3(gl_GlobalInvocationID.xyz);
	const vec3 uvw = gl_GlobalInvocationID.xyz * InvVolumeDimensions;

	// spatial interpolation
	const warp_local current_warp = textureLod(pingpongTexture[pc.index_input], uvw, 0);

	const vec3 current_location = uvw * WorldDimensions;

	float t0, d0;
	// #################################################################################################################
	{	// distance & direction ###
		
		vec4 current_direction_distance = emitter_to_direction_distance(current_warp.emitter_location, current_location);
		current_direction_distance.xyz = transformNormalToViewSpace(mat3(pc.view), current_direction_distance.xzy).xzy;  // transforming a direction does not have any position information from view matrix, so the fractional offset it contains is not inadvertently added here.

		// temporal interpolation 
		current_direction_distance.w = normalize_distance(current_direction_distance.w);
		const float original_distance = current_direction_distance.w;

		temporalBlendDD(inTemporalDD[pc.index_filter], current_direction_distance.xyz, current_direction_distance.w, uvw);

		// ### temporal supersampled output - result moves to output

		// // get absolute difference (for vectors, the data, does not require usage of abs)
		// see: https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixsub.htm
		{
			const float diff_distance = current_direction_distance.w - original_distance; // no abs is important
			current_direction_distance.w = current_direction_distance.w - diff_distance;
			d0 = current_direction_distance.w * 0.5f + 0.5f;
			t0 = d0 / (original_distance * 0.5f + 0.5f); // this parameter is only for *color*
		}

		imageStore(outTemporalDD[1 - pc.index_filter], iLocation, current_direction_distance);

		
		imageStore(outTemporalDD[2], iLocation, current_direction_distance);
	}

	{   // color ###
		const vec3 current_color = unpackColor(current_warp.packed_color); //mix(unpackColor(last_warp.packed_color), unpackColor(current_warp.packed_color), 0.5f);

		{ // light
			// Input sample of blended area, see : 
			// https://www.shadertoy.com/view/fdjXDD

			// d0 is currently normalized to range [0.0f ... 1.0f]
			vec3 current_light_color = sampleC(pingpongTexture[pc.index_input], current_color, current_location, d0);

			current_light_color = temporalBlendC(inTemporalC[pc.index_filter], inTemporalDD[pc.index_filter], current_light_color, uvw, d0);

			// ### temporal supersampled output - result moves to output

			// this auto corrects too much temporal feedback from history frames (trails bug)
			// its not introducing jitter (shaky light)
			// has still a little temporal feedback but is limited unlike before
			// only apply to color, is based off of the signed distance above. -apply to direction causes more weird things.
			current_light_color = mix(current_color, current_light_color, t0);
			
			imageStore(outTemporalC[1 - pc.index_filter], iLocation, current_light_color.rgbb);
			imageStore(outTemporalCFinal, iLocation, vec4(current_light_color.rgb, 1.0f));
		}

		{ // reflection
			vec3 current_reflect_color = temporalBlendR(inTemporalR[pc.index_filter], current_color, uvw);

			// ### temporal supersampled output - result moves to output

			// this auto corrects too much temporal feedback from history frames (trails bug)
			// its not introducing jitter (shaky light)
			// has still a little temporal feedback but is limited unlike before
			// only apply to color, is based off of the signed distance above. -apply to direction causes more weird things.
			current_reflect_color = mix(current_color, current_reflect_color, t0);

			imageStore(outTemporalR[1 - pc.index_filter], iLocation, current_reflect_color.rgbb);
			imageStore(outTemporalR[2], iLocation, vec4(current_reflect_color.rgb, 1.0f));
		}
	}



/*
	
	vec4 temporal_volume_sum_direction_distance;
	vec3 temporal_volume_sum_color;
	
	const ivec3 iLocation = ivec3(gl_GlobalInvocationID.xyz);
	
	{ // input index is off by one for final accumulated output is no included. Only the raw current values propogate thru the temporal history

		// ### sample oldest (1), begin result. note: this volume gets popped off the "queue"
		temporal_volume_sum_direction_distance = texelFetch(inTemporalDD[1], iLocation, 0);								// read 2
		temporal_volume_sum_color = texelFetch(inTemporalC[1], iLocation, 0).rgb;										// read 2

		{ // ### sample old, add to result, then old moves to 1. note: this volume gets popped to back of "queue"
			{
				const vec4 temporal_volume = texelFetch(inTemporalDD[0], iLocation, 0);									// read 1
				temporal_volume_sum_direction_distance += temporal_volume;					
				imageStore(outTemporalDD[2], iLocation, temporal_volume);												// overwrite 2 with 1
			}
			{
				const vec3 temporal_volume = texelFetch(inTemporalC[0], iLocation, 0).rgb;								// read 1
				temporal_volume_sum_color += temporal_volume;
				imageStore(outTemporalC[2], iLocation, temporal_volume.rgbb);											// overwrite 2 with 1
			}	
		}
	}
	
	#define _direction xyz
	#define _distance a

	// sample new, add to result, then new moves to 0. note: this volume gets pushed to front of "queue"

	{   // sampling ###
		vec3 source_location;
		{
			vec3 source_color;
			sampleInputVolumeAA(source_location, source_color, iLocation);

			// color ###
			temporalBlendC(source_color);

			imageStore(outTemporalC[1], iLocation, source_color.rgbb);													// overwrite 1 with current
			temporal_volume_sum_color += source_color;

			// ### temporal supersampled output - result moves to output
			temporal_volume_sum_color = temporal_volume_sum_color * pc.inv_temporal_size;
			imageStore(outTemporalC[0], iLocation, temporal_volume_sum_color.rgbb);										// overwrite 0 with accumulated (final output)
		}

		// distance & direction ###
		const vec3 current_location = gl_GlobalInvocationID.xyz * InvVolumeDimensions * WorldDimensions;
		const vec3 direction = source_location - current_location;

		// normalization
		vec4 source;
		source._distance = length(direction) * pc.inv_max_distance * 2.0f - 1.0f;  // normalized distance, expanded to [-1.0f...1.0f] to leverage full range of 16bit signed texture
		// transforms world space position of light to view space
		// mat3 of view only required to transform a normal / direction vector		// this is a bug fix weird but works well enough 
																					// this is the half angle between light direction and view'ish vector
																					// eliminates most of the "bright building" in top left corner problem
																					// other option is to completely rip out direction which won't look as good
																					// its a hack but - its satisfactory visually (hard problem to solve this late with lighting being "done")

		source._direction = transformNormalToViewSpace(mat3(pc.view), normalize(direction).xzy).xzy;  // direction is natively width,depth,height
																					// view is width, height, depth
																					// so the mul, direction is swizzled to be compatible with view
																					// then finally swizzled back to width,depth,height
																					// which is the final form we want for fragment shaders
		const float saved_raw_distance = source._distance;

		temporalBlendDD(source._direction, source._distance, iLocation);

		imageStore(outTemporalDD[1], iLocation, source);	
		temporal_volume_sum_direction_distance += source;

		// ### temporal supersampled output - result moves to output

		// // get absolute difference (for vectors, the data, does not require usuage of abs)
		// see: https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixsub.htm
		temporal_volume_sum_direction_distance = temporal_volume_sum_direction_distance * pc.inv_temporal_size;
		const float distance_diff = (temporal_volume_sum_direction_distance._distance - saved_raw_distance); // no abs is important
		temporal_volume_sum_direction_distance._distance = temporal_volume_sum_direction_distance._distance - distance_diff; // remove difference - removes ghosting
													// only distance needs this correction
													// direction alone has no ghosting effect, and is supersampled without correction
	
		imageStore(outTemporalDD[0], iLocation, temporal_volume_sum_direction_distance);
	}
*/
}
#endif



