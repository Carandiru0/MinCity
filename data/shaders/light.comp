#version 460
#extension GL_GOOGLE_include_directive : enable
//#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_ballot: enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
//#extension GL_KHR_shader_subgroup_shuffle: enable
//#extension GL_KHR_shader_subgroup_quad : enable
#extension GL_EXT_control_flow_attributes : enable

/* Copyright (C) 20xx Jason Tully - All Rights Reserved
 * You may use, distribute and modify this code under the
 * terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License
 * http://www.supersinfulsilicon.com/
 *
This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/
or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.
 */

#include "common.glsl"
#include "transform.glsl"
#include "shareduniform.glsl"

#define GROUP_SIZE_XYZ 8

layout (local_size_x = GROUP_SIZE_XYZ, local_size_y = GROUP_SIZE_XYZ, local_size_z = GROUP_SIZE_XYZ) in;	// z is manually set/tweaked see volumetricOpacity.h 8,8,8=256 tested optimal warp size at height 128 and 256 visible voxels

// SEED uses PING output, hardcoded, however SEED input requires pc.index_input
layout (push_constant) restrict readonly uniform PushConstant {
	layout(offset=0) int		current_step;		//  JFA
	layout(offset=4) uint		index_output;		// __---->_________________________________________________________________
	layout(offset=8) uint		index_input;        // __<----_________________________________________________________________
} pc;

#define LIGHT 0
#define OPACITY 1

layout (binding = 1) uniform sampler3D seedMap;	// lightprobe map
layout (binding = 2) uniform sampler3D pingpongTexture[2]; // sampling the "ping"
layout (binding = 3, rgba32f) writeonly restrict uniform image3D pingpongImage[2];	// storing the "pong", -only to be used with imageStore (writeonly)
//////////////////////////////////////////////////////////////////////////////////
layout (binding = 4, rg16_snorm) writeonly restrict uniform image3D outTemporalDDFinal; // (distance & direction) final filtered output + n temporal history volumes -only to be used with imageStore (writeonly) // only signed normalized values
layout (binding = 5, rgba16f) writeonly restrict uniform image3D outTemporalCFinal; // (color) final filtered output
layout (binding = 6, rgba8) writeonly restrict uniform image3D outTemporalRFinal; // (reflection color) final filtered output + n temporal history volumes -only to be used with imageStore (writeonly)

// "World Visible Volume"
layout (constant_id = 0) const float WorldDimensions = 0.0f;
layout (constant_id = 1) const float InvWorldLength = 0.0f;

// "Light Volume"
layout (constant_id = 2) const float VolumeDimensions = 0.0f;
layout (constant_id = 3) const float InvVolumeDimensions = 0.0f;

#define emitter_location xyz
#define packed_color a
#define warp_local vec4

// seed uses the source uploaded light, selecting the correct input based on the current frames resource index
vec4 sampleInputVolume( in restrict sampler3D map, in const vec3 read_location )
{
//#ifdef SEED
//	return( textureLod(map, (read_location + 0.5f) * InvVolumeDimensions, 0) );
//#else
	return( texelFetch(map, ivec3(floor(read_location)), 0) );
//#endif
}
#ifdef SEED
vec4 sampleInputVolume( in const vec3 read_location )
{
/*
	// temporal interpolation (last frames output is always the opposite index of this frames output so writes and reads never overlap)
	warp_local now = sampleInputVolume(seedMap, read_location);
	now.xyz = transformPositionToViewSpace(u._view, now.xzy).xzy;

	warp_local last = sampleInputVolume(pingpongTexture[pc.index_input], read_location);
	last.xyz = transformPositionToViewSpace(u._view, last.xzy).xzy;

	// interpolate only lit positions
	if ( all(notEqual(vec2(now.packed_color, last.packed_color), vec2(0))) ) {	// new
		now.xyz = mix(last.xyz, now.xyz, 0.95f);
		now.packed_color = packColor(mix(unpackColor(last.packed_color), unpackColor(now.packed_color), 0.95f));
	} 
	
	return( now );
*/	

	return(sampleInputVolume(seedMap, read_location));
}
#else
vec4 sampleInputVolume( in const vec3 read_location )
{
	return(sampleInputVolume(pingpongTexture[pc.index_input], read_location));
}
#endif

// ###################################################################################################################################
#if !defined(MIP)
shared vec4 warp_lds[GROUP_SIZE_XYZ][GROUP_SIZE_XYZ][GROUP_SIZE_XYZ];

#define localToGlobal(local) fma(gl_WorkGroupID.xyz, vec3(GROUP_SIZE_XYZ), local)

vec4 populateLDS(in const ivec3 local_location) {

	const warp_local warp = sampleInputVolume(localToGlobal(local_location));
	warp_lds[local_location.x][local_location.y][local_location.z] = warp;

	// barrier moved to propogateBlocks
	return( warp );
}
//vec3(VolumeDimensions_Width, VolumeDimensions_Depth, VolumeDimensions_Height)
vec4 group_load( in const ivec3 local_location ) {

	const bool bZero = all(greaterThanEqual(local_location, ivec3(0)));
	const bool bGroup = bZero && all(lessThan(local_location, ivec3(GROUP_SIZE_XYZ)));

	[[branch]] if (subgroupAll( bGroup ) || bGroup) { // fast subgroup & group paths

		return( warp_lds[local_location.x][local_location.y][local_location.z] );
	}
	// regular path - border texture addressing on texture sampler so out of bounds are handled with no light returned.
	return( sampleInputVolume(localToGlobal(local_location)) );
	
	/*
	return(
	subgroupAll(all(greaterThanEqual(location, ivec3(0))) && all(lessThan(location, ivec3(GROUP_SIZE)))) ?
		warp_lds[location.x][location.y][location.z]
		:
		sampleInputVolume(ilocalToGlobal(location))
	);
	*/
}

void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	if ( 0.0f != read_warp.packed_color ) {	// new
			
		const float read_distance = distance(read_warp.emitter_location, current_location);

		const bool bLess = read_distance < current_distance;
			
		movc(bLess, current_distance, read_distance);
		movc(bLess, warp, read_warp);
	}
}

/*
void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	[[branch]] if ( isLit(read_warp.packed_color) ) {	// new
			
		const float read_distance = distance(read_warp.emitter_location, current_location);

		current_distance = subgroupMin(read_distance);
		
		// acquire id of the active invocation that contains the least distance
		const uint active_invocation_id = subgroupBallotFindMSB(subgroupBallot(read_distance == current_distance));
		
		// every other invocation acquires the active_invocation's warp, which is the location and color of the light that was deemed the closest across the entire subgroup.
		warp = subgroupShuffle(read_warp, active_invocation_id);
	}
}
*/

/*
void propogateBlock(inout warp_local warp, inout float current_distance, in const vec3 current_location, in const ivec3 read_location) {

	const warp_local read_warp = group_load(read_location);

	const bool lit = isLit(read_warp.packed_color);
	const float read_distance = lit ? distance(read_warp.emitter_location, current_location) : 99999.99999f;

	current_distance = subgroupMin(read_distance);

	// acquire id of the active invocation that contains the least distance
	const uint active_invocation_id = subgroupBallotFindMSB(subgroupBallot(read_distance == current_distance));
		
	// every other invocation acquires the active_invocation's warp, which is the location and color of the light that was deemed the closest across the entire subgroup.
	[[branch]] if ( isLit(read_warp.packed_color) ) {	// new
		
	
	warp = subgroupShuffle(read_warp, active_invocation_id);

	}
}*/

// 26 neighbours (no center sample) [optimal memory access pattern]
const ivec3 offsets[] = ivec3[]( ivec3(-1, -1, -1),
								 ivec3(0, -1, -1),
								 ivec3(1, -1, -1),
								 ivec3(-1, 0, -1),
								 ivec3(0, 0, -1),
								 ivec3(1, 0, -1),
								 ivec3(-1, 1, -1),
								 ivec3(0, 1, -1),
								 ivec3(1, 1, -1),
								
								 ivec3(-1, -1, 0),
								 ivec3(0, -1, 0),
								 ivec3(1, -1, 0),
								 ivec3(-1, 0, 0),
								 ivec3(1, 0, 0),
								 ivec3(-1, 1, 0),
								 ivec3(0, 1, 0),
								 ivec3(1, 1, 0),
								
								 ivec3(-1, -1, 1),
								 ivec3(0, -1, 1),
								 ivec3(1, -1, 1),
								 ivec3(-1, 0, 1),
								 ivec3(0, 0, 1),
								 ivec3(1, 0, 1),
								 ivec3(-1, 1, 1),
								 ivec3(0, 1, 1),
								 ivec3(1, 1, 1) );


void propogateBlocks(inout warp_local warp, in const vec3 current_location)
{
	const int current_step = pc.current_step;

	float current_distance = ((0.0f != warp.packed_color) ? distance(warp.emitter_location, current_location) : 99999999999.9f);
	
	for (uint i = 0u ; i < offsets.length() ; ++i) {
		propogateBlock(warp, current_distance, current_location, ivec3(gl_LocalInvocationID.xyz) + offsets[i] * current_step);
	}
	
}

void main() 
{
	const vec3 global_invocation_id = localToGlobal(gl_LocalInvocationID.xyz);

	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(global_invocation_id - VolumeDimensions, vec3(0))) )
			return;
	}

	warp_local warp = populateLDS(ivec3(gl_LocalInvocationID.xyz));  // value is properly initialized.

#ifndef SEED // idealy SEED runs as 1+ JFA
	
	barrier(); // required so that lds is coherent between the last writes and now reads (memorybarriershared is included in barrier too)

	propogateBlocks(warp, (global_invocation_id * InvVolumeDimensions * WorldDimensions));
#endif
	imageStore(pingpongImage[pc.index_output], ivec3(localToGlobal(gl_LocalInvocationID.xyz)), warp);
}

#endif // not MIP


// ###################################################################################################################################
#if defined(MIP) // FILTER STEP
								
float emitter_to_distance(in const vec3 emitter_location, in const vec3 current_location)
{
	return(distance(emitter_location, current_location));
}
float normalize_distance(in const float d) // normalized distance, [0.0f ... 1.0f]
{
	return(clamp(d * InvWorldLength, 0.0f, 1.0f));
}
vec3 emitter_to_direction(in const vec3 emitter_location, in const vec3 current_location)
{
	return(normalize(emitter_location - current_location));
}
vec4 emitter_to_direction_distance(in const vec3 emitter_location, in const vec3 current_location)
{
	vec4 current_direction_distance;
	current_direction_distance.xyz = (emitter_location - current_location);
	current_direction_distance.w = length(current_direction_distance.xyz);							// optimized normalized direction + distance with one less sqrt
	current_direction_distance.xyz = current_direction_distance.xyz / current_direction_distance.w; // <---normalized

	return(current_direction_distance);
}

/* deprecated for non temporal replacement sample_warp()
// smin removes discontuities (voronoi edges) by blending distance field data correctly
void temporalBlendDD( in const restrict sampler3D inputTemporalDD, inout vec3 direction, inout float dist, in const vec3 uvw )
{
	// input Distance, Direction, are initialized to the locations first sample
	const float blending = 0.01f;
	vec4 neighbour;

	neighbour = textureLod(inputTemporalDD, fma(vec3(-0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0.5f,0,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,-0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0.5f,0), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,-0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]

	neighbour = textureLod(inputTemporalDD, fma(vec3(0,0,0.5f), InvVolumeDimensions, uvw), 0);
	direction = normalize(normalize(neighbour.xyz) + direction);
	dist = smin(dist, neighbour.w * 0.5f + 0.5f, blending); // signed texture sample - range [-1,1] convert to [0,1]
}		
*/
/*
vec3 temporalBlendR( in const restrict sampler3D inputTemporalR, in vec3 color, in const vec3 uvw )
{
	// input color is initialized to the locations first sample

	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalR, uvw, 0, ivec3(0,0,1)).rgb;

	return(color * (1.0f/7.0f)); // 6 neighbour samples + 1 center sample
}
*/
/*float attenuation(in const float d)
{
	return(1.0f / fma(d, d, 1.0f));
}
*/
// final inverse square law equation used:
// a = 1.0 / sqrt(d*d + 1.0)  [compute shader]   - light color is pre-multiplied by this equation
// b = 1.0 / sqrt(d*d + 1.0)  [fragment shader]  - the light color is multiplied again by this equation
// final attenuation is then b*a*color
// see : https://www.desmos.com/calculator/qlxe8vxuzh
float attenuation(in float light_distance)  // this is half of the equation, when light volume is sampled, the other half is calculated. They than combine to make the full equation as above. This seems to be the most accurate for distance.
{
	return( 1.0f / sqrt(fma(light_distance,light_distance,1.0f)) );
}

/*
vec3 temporalBlendC( in const restrict sampler3D inputTemporalC, in const restrict sampler3D inputTemporalDD, in vec3 color, in const vec3 uvw, in const float d0 )
{
	// this is the correct physical way of blending colors of light, additive blending of adjacent light colors (no mixing)
	// with additive blending light will accumulate to white in area's of bright mixed colors as it correctly should intensify with nearby lighting

	float emission = attenuation(d0);

	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(-1,0,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(1,0,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,-1,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,1,0)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,-1)).a * 0.5f + 0.5f);
	emission += attenuation(textureLodOffset(inputTemporalDD, uvw, 0, ivec3(0,0,1)).a * 0.5f + 0.5f);

	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(-1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(1,0,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,-1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,1,0)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,-1)).rgb;
	color += textureLodOffset(inputTemporalC, uvw, 0, ivec3(0,0,1)).rgb;

	// "One important note here is that we normalise pixel emissive on total number of rays, but pixel colour on the 
	// total accumulated emissive. This means the colour value maintains it’s magnitude (or brightness) regardless 
	// of how many rays were cast or surfaces hit. E.g. if we cast 32 rays and only 1 of them hit a red emitter, 
	// we want all of that red colour to contribute to the final pixel colour."
	// https://samuelbigos.github.io/posts/2dgi1-2d-global-illumination-in-godot.html

	// 7 samples total
	color /= emission;
	emission /= 7.0f;

	return(emission * color);
}
*/
				
// this function removes the edges in the voronoi structure by making neighbours accurate (minimum distance to light/per voxel)
// it also calculates the lighting color contributed by all neighbours
void sample_warp(in const restrict sampler3D pingpong, in const ivec3 uvw, inout vec4 current_direction_distance, inout vec3 current_color, in const vec3 current_location) 
{	
	warp_local neighbour_warp;
	vec4 neighbour_direction_distance;

	// 1 center
	current_color = current_color * attenuation(current_direction_distance.w);
		
	// 26 neighbours
	
	// 1
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1,-1,-1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);

	// 2
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, -1, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 3
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, -1, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 4
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 0, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 5
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, 0, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 6
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 0, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 7
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 1, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 8
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, 1, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 9
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 1, -1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 10
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, -1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 11
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, -1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 12
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, -1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 13
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 0, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 14
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 0, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 15
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 16
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, 1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 17
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 1, 0)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 18
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, -1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 19
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, -1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 20
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, -1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 21
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 0, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 22
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, 0, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 23
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 0, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 24
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(-1, 1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 25
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(0, 1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
	
	// 26
	neighbour_warp = texelFetchOffset(pingpong, uvw, 0, ivec3(1, 1, 1)); //
	neighbour_direction_distance = emitter_to_direction_distance(neighbour_warp.emitter_location, current_location);
	current_color += unpackColor(neighbour_warp.w) * attenuation(neighbour_direction_distance.w);
	movc(neighbour_direction_distance.w < current_direction_distance.w, current_direction_distance.xyz, neighbour_direction_distance.xyz);
	current_direction_distance.w = min(current_direction_distance.w, neighbour_direction_distance.w);
}
	

//const vec3 fix_direction = normalize(vec3(1,0,-1));
void main() 
{
	{ // #### Required Bounds Check //
		if ( any(greaterThanEqual(gl_GlobalInvocationID.xyz - VolumeDimensions, vec3(0))) )
			return;
	}

	const warp_local current_warp = texelFetch(pingpongTexture[pc.index_input], ivec3(gl_GlobalInvocationID.xyz), 0);
	vec3 current_color = unpackColor(current_warp.packed_color);

	// #################################################################################################################
	{	// distance & direction ###
		
		const vec3 current_location = (gl_GlobalInvocationID.xyz * InvVolumeDimensions * WorldDimensions);

		vec4 current_direction_distance = emitter_to_direction_distance(current_warp.emitter_location, current_location);
		
		sample_warp(pingpongTexture[pc.index_input], ivec3(gl_GlobalInvocationID.xyz), current_direction_distance, current_color, current_location);

		// view is in xyz form, must swizzle direction to xzy form to be xyz form match the view. On output, swizzled back to xzy form as that is the standard for the volumes best data layout. (x = width, z = depth, y = height/slice)
		current_direction_distance.xzy = transformNormalToViewSpace(mat3(u._view), current_direction_distance.xzy);
		current_direction_distance.w = normalize_distance(current_direction_distance.w) * 2.0f - 1.0f; // expand distance to range [-1,1] for signed texture precision usage
		
		imageStore(outTemporalDDFinal, ivec3(gl_GlobalInvocationID.xyz), current_direction_distance);
	}

	{   // color ###
		
		{ // light
			// Input sample of blended area, see : 
			// https://www.shadertoy.com/view/fdjXDD

			// d0 is currently normalized to range [0.0f ... 1.0f]
			//vec3 current_light_color = sampleC(pingpongTexture[pc.index_input], current_color, current_location, d0);
			//const float att = attenuation(d0);
			//current_light_color = current_color * att + current_light_color * att; // light color target is 16bpc float so the intensity increases for light nicely based off distance
			
			imageStore(outTemporalCFinal, ivec3(gl_GlobalInvocationID.xyz), vec4(current_color.rgb, 1.0f));
		}

		{ // reflection
			imageStore(outTemporalRFinal, ivec3(gl_GlobalInvocationID.xyz), vec4(current_color.rgb, 1.0f)); // reflection color is 8bpc, just store the color.
		}
	}



/*
	
	vec4 temporal_volume_sum_direction_distance;
	vec3 temporal_volume_sum_color;
	
	const ivec3 iLocation = ivec3(gl_GlobalInvocationID.xyz);
	
	{ // input index is off by one for final accumulated output is no included. Only the raw current values propogate thru the temporal history

		// ### sample oldest (1), begin result. note: this volume gets popped off the "queue"
		temporal_volume_sum_direction_distance = texelFetch(inTemporalDD[1], iLocation, 0);								// read 2
		temporal_volume_sum_color = texelFetch(inTemporalC[1], iLocation, 0).rgb;										// read 2

		{ // ### sample old, add to result, then old moves to 1. note: this volume gets popped to back of "queue"
			{
				const vec4 temporal_volume = texelFetch(inTemporalDD[0], iLocation, 0);									// read 1
				temporal_volume_sum_direction_distance += temporal_volume;					
				imageStore(outTemporalDD[2], iLocation, temporal_volume);												// overwrite 2 with 1
			}
			{
				const vec3 temporal_volume = texelFetch(inTemporalC[0], iLocation, 0).rgb;								// read 1
				temporal_volume_sum_color += temporal_volume;
				imageStore(outTemporalC[2], iLocation, temporal_volume.rgbb);											// overwrite 2 with 1
			}	
		}
	}
	
	#define _direction xyz
	#define _distance a

	// sample new, add to result, then new moves to 0. note: this volume gets pushed to front of "queue"

	{   // sampling ###
		vec3 source_location;
		{
			vec3 source_color;
			sampleInputVolumeAA(source_location, source_color, iLocation);

			// color ###
			temporalBlendC(source_color);

			imageStore(outTemporalC[1], iLocation, source_color.rgbb);													// overwrite 1 with current
			temporal_volume_sum_color += source_color;

			// ### temporal supersampled output - result moves to output
			temporal_volume_sum_color = temporal_volume_sum_color * pc.inv_temporal_size;
			imageStore(outTemporalC[0], iLocation, temporal_volume_sum_color.rgbb);										// overwrite 0 with accumulated (final output)
		}

		// distance & direction ###
		const vec3 current_location = gl_GlobalInvocationID.xyz * InvVolumeDimensions * WorldDimensions;
		const vec3 direction = source_location - current_location;

		// normalization
		vec4 source;
		source._distance = length(direction) * pc.inv_max_distance * 2.0f - 1.0f;  // normalized distance, expanded to [-1.0f...1.0f] to leverage full range of 16bit signed texture
		// transforms world space position of light to view space
		// mat3 of view only required to transform a normal / direction vector		// this is a bug fix weird but works well enough 
																					// this is the half angle between light direction and view'ish vector
																					// eliminates most of the "bright building" in top left corner problem
																					// other option is to completely rip out direction which won't look as good
																					// its a hack but - its satisfactory visually (hard problem to solve this late with lighting being "done")

		source._direction = transformNormalToViewSpace(mat3(pc.view), normalize(direction).xzy).xzy;  // direction is natively width,depth,height
																					// view is width, height, depth
																					// so the mul, direction is swizzled to be compatible with view
																					// then finally swizzled back to width,depth,height
																					// which is the final form we want for fragment shaders
		const float saved_raw_distance = source._distance;

		temporalBlendDD(source._direction, source._distance, iLocation);

		imageStore(outTemporalDD[1], iLocation, source);	
		temporal_volume_sum_direction_distance += source;

		// ### temporal supersampled output - result moves to output

		// // get absolute difference (for vectors, the data, does not require usuage of abs)
		// see: https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixsub.htm
		temporal_volume_sum_direction_distance = temporal_volume_sum_direction_distance * pc.inv_temporal_size;
		const float distance_diff = (temporal_volume_sum_direction_distance._distance - saved_raw_distance); // no abs is important
		temporal_volume_sum_direction_distance._distance = temporal_volume_sum_direction_distance._distance - distance_diff; // remove difference - removes ghosting
													// only distance needs this correction
													// direction alone has no ghosting effect, and is supersampled without correction
	
		imageStore(outTemporalDD[0], iLocation, temporal_volume_sum_direction_distance);
	}
*/
}
#endif



